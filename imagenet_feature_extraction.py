import fire
import os
import pandas as pd
import numpy as np
import re

import torch
from torch.utils.data import DataLoader

from data_loader import ImageDataset
import encoder_models.ResNet as resnet
import encoder_models.VGG as vgg
import encoder_models.DINO as dino


class FeatureExtractor:
    """
    This class performs the forward pass and extracts the features
    """

    def __init__(self, imgs_path: str, model_name: str, img_type: str = 'png',
                 batch_size: int = 128, normalize: bool = False, crop: int = None,
                 focus_on_centre: bool = False):
        self.imgs_path = imgs_path
        self.model_name = model_name
        self.img_type = img_type
        self.crop = crop
        self.normalize = normalize
        self.focus_on_centre = focus_on_centre
        self.batch_size = batch_size

    @property
    def model(self):
        # classifier is removed in the forward pass (see file in encoder_models)
        model_category = re.match('^[^_\d]*', self.model_name).group(0)
        model_fct = eval(f'{model_category}.{self.model_name}')
        model = model_fct(pretrained=True)

        return model

    @property
    def transforms(self):
        return self.data.pre_process

    @property
    def data(self):
        return ImageDataset(root_dir=self.imgs_path, expected_input_size=self.model.expected_input_size,
                            img_type=self.img_type, crop=self.crop, normalize=self.normalize,
                            focus_on_centre=self.focus_on_centre)

    def get_features(self):
        dataloader = DataLoader(self.data, batch_size=self.batch_size, num_workers=0)
        features = {}
        for i_batch, (img_batch, filename_batch) in enumerate(dataloader):
            self.model.eval()
            # Forward Pass
            with torch.no_grad():
                output_batch = self.model(img_batch)
                # save the output features
                assert len(output_batch) == len(filename_batch)
                for fn, output in zip(list(filename_batch), output_batch):
                    features[fn] = np.array(output)

        return features


def extract_imagenet_features(imgs_folder: str, output_path: str, model: str, multifolder: bool = False, img_type: str = 'png',
                              overwrite: bool = False, normalize: bool = False, crop: int = None, focus_on_centre: bool = False):
    """
    This function creates a csv file with features generated by a forward pass through an ImageNet pre-trained network
    for given images.

    :param focus_on_centre:
    :param normalize:
    :param imgs_folder: string
        Path where the images are located. (also see multifolder argument to process multiple folders within a root folder)
    :param output_path: string
        Path where the feature csv file should be saved to.
    :param model: string
        Model name (e.g. resnet18). Check files in encoder_models to see what is available.
    :param multifolder: bool (optional)
        Default False. Set if the specified imgs_path contains multiple folders with images, that should all be processed.
    :param img_type: string (optional)
        Default is "png". Image type to look for.
    :param overwrite: bool (optional)
        Default is False. If set to True, existing files will be overwritten.
    :param crop: int (optional)
        Default is None. If set, a centre crop will be generated from the patch of the specified size
    """

    if not os.path.isdir(output_path):
        os.makedirs(output_path, exist_ok=True)

    if not multifolder:
        subfolders = [imgs_folder]
    else:
        subfolders = [os.path.join(imgs_folder, o) for o in os.listdir(imgs_folder) if
                      os.path.isdir(os.path.join(imgs_folder, o))]

    for subfolder in sorted(subfolders):
        folder_name = os.path.basename(subfolder)
        csv_path = os.path.join(output_path, f'{folder_name}-{model}-patch-features.csv')

        if not os.path.isfile(csv_path) or overwrite:
            print(f'Processing folder {folder_name}...')
            feature_extractor = FeatureExtractor(imgs_path=subfolder, model_name=model, img_type=img_type,
                                                 crop=crop, normalize=normalize, focus_on_centre=focus_on_centre)
            features = feature_extractor.get_features()

            # create the data frame and save it
            features_dict = {int(re.search('\D+_(\d+)_', img_name).group(1)): (img_name, features) for img_name, features
                             in features.items()}
            df_features = pd.DataFrame.from_dict({k: v[1] for k, v in features_dict.items()},
                                                 orient='index').sort_index()
            df_features.rename(columns={i: f'{model}_f{i}' for i in df_features.columns}, inplace=True)

            df_names = pd.DataFrame.from_dict({k: v[0] for k, v in features_dict.items()},
                                              orient='index').sort_index()
            df_names.rename(columns={0: 'filename'}, inplace=True)

            df = pd.concat([df_names, df_features], axis=1)

            df.to_csv(csv_path)

    with open(os.path.join(output_path, 'transforms.txt'), 'w') as f:
        f.write(str(feature_extractor.transforms))


if __name__ == '__main__':
    fire.Fire(extract_imagenet_features)
